# NHDL Analysis Scripts

This directory contains primarily 3 scripts:
- harvestOAI.py
- analyzeCDM.py
- recon.py

These are Python 3 scripts used to run basic tasks used in the analysis, mapping and normalization rules written in the XSLT in this repository. They are not necessary for running the XSLT files, but they are helpful for changing and enhancing them.

These are derived from work originally based on the following:
- [pyoaiharvester](https://github.com/vphill/pyoaiharvester)
- [metadata_breakers](https://github.com/vphill/metadata_breakers)
- [Metadata Analysis at the Command Line](http://journal.code4lib.org/articles/7818)

## Requirements

- Python (preferably 3.7; follow .python-version in top level); Untested on Python 2.
- pipenv (and pip; usually included with modern installations of Python 3).

## Install

We run the Python & Bash commands within a pipenv shell where our requirements are installed from the Pipfile.lock generated by our Pipfile. To setup the pipenv shell & install required libraries:

1. Get this repository on your computer somehow. You can:
    1. change to file location where you want these scripts, then clone this git repository to your computer:
    ```
    $ git clone https://github.com/cmharlow/nhdl-mdx.git
    ```
    1. download this repository to your computer from the GitHub page - use the 'Download Zip' button in bottom right corner. Move the zip file to the place you wish to have these scripts, then unzip.
2. Change into the analysis scripts directory:
  ```
  $ cd analysisScripts/
  ```
3. run `pipenv install`
4. run `pipenv shell`

Now you should be ready to use the scripts. When you are done, close the pipenv shell via running `deactivate`

## Harvesting OAI Feed

usage: python oaiharvest.py [options, see below] -l link to OAI feed -o file to save to.

optional arguments:

- -h: a help message
- -l: URL of OAI repository (defaults to `http://digitalcollections.plymouth.edu/oai/oai.php`)
- -o: write repository to this file
- -f: harvest records from this date yyyy-mm-dd
- -u: harvest records until this date yyyy-mm-dd
- -m: use the specified metadata format (defaults to `oai_qdc`)
- -s: harvest the specified set

This downloads all the QDC/XML data from the OAI feed at Plymouth State University, and saves it to the file 'sample.qdc.xml'.
```
$ python oaiharvest.py -m qdc -o sample.qdc.xml
```

## Analysis

All of the analysis scripts run similarly to what is described by Mark Phillips here for his own work: [Metadata Analysis at the Command Line](http://journal.code4lib.org/articles/7818)

usage: oaidc_analysis.py data_filename.xml [options, see below]

positional arguments:

- datafile              put the datafile you want analyzed here

optional arguments:

- -h: show a help message
- -e: element to print to screen (use known prefixes like `qdc`, `dcterms`, `dc`, `edm`)
- -i: prepend meta_id/OAI header id for record to line
- -s: only print stats for repository (default)
- -p: print TRUE / FALSE if there is value of defined element in record

To get a field report:

```
$ python analysisCDM.py sample.qdc.xml
```

To get all the values for the dc:creator field:

```
$ python analysisCDM.py sample.qdc.xml -e dc:creator  
```

To get all the unique values for the dc:creator field, sorted by count, using bash:

```
$ python analysisCDM.py test/output.xml -e dc:creator | sort | uniq -c  
```

## Lookup XSLT (e.g. remediation.xslt) Generation & Updates

The `recon.py` script imports `lookupAPIs.py`, `parseXML.py`, and `reconLookups.py` to take in an existing `remediation.xslt` file, read a harvested OAI xml file (like `p15828coll1.qdc.xml`), and update a given param set in `remediation.xslt` with more findings from a given authority.

It is written primarily to work with Spatial strings, parse them from the XML, match them against Geonames API ([with a limited number of calls each day for your free account](http://www.geonames.org/login)), and put the results (original search string, Geonames Label, Geonames URI, Geonames Coordinates) into an updated `reconciled-remediation.xslt` file. This file then can be used with the XSLT (rename it as `xslt/remediation.xslt` or rename and import it into Combine) to match XML values within `dcterms:spatial` to the NHDL spatial MAP fields for label, URI, and coordinates.

This is an approach made to work against the current DPLA recommendations and processes for geo-spatial data in particular; namely, they use the strings provided to lookup coordinates, and have less of a use currently for geo-spatial data URIs. See the DPLA Geographic guidelines here: https://docs.google.com/document/d/1b2iJI90I24hUp-8kCfnZhAQcefBt0vPUjMzhDn9HOZ0/edit.

To run a OAI harvested files through this `recon.py` script:

```
$ python recon.py -d ';' p15828coll7.qdc.xml
```

This leverages a few defaults - `remediation.xslt` (the file read in & updated) is in the same directory; the element matched against from the OAI harvest file is `dcterms:spatial`; and the output param in `remediation.xslt` is `geonamesLocation`. It also says to split the values from the OAI harvest file on `;` via the -d argument.

The output will be `reconciled-remediation.xslt` with the updated geonamesLocation parameter.

Nota bene:
- you will need to tweak namespaces for this to work currently for reloading into XSLT;
- added lines will not have pretty-print structure, as a trade-off to not add large classes to the environment - they will be valid XML however;
- it will ignore existing values in the `remediation.xslt` param & other params (copy over to the new file);
- you can also create a lookup table and add it into the `remediation.xslt` file, in case you want to generate these lookup values in something like OpenRefine or manually update certain values (like add a typo match);
- this recon.py script is built around Geonames lookups, but is structured so it could be expanded to do other lookups if needed / wanted. See the CLI args setup for how it could be modified:

```
$ python recon.py --help

positional arguments:
  file                  datafile you want parsed for reconciliation values

optional arguments:
  -h, --help            show this help message and exit
  -d DELIMITER, --delimiter DELIMITER
                        delimiter to split the field value on.
  -e ELEMENT, --element ELEMENT
                        element to reconcile
  -r RECONCILED, --reconciled RECONCILED
                        name of file with reconciled XSL dictionary.
  -p PARAM, --param PARAM
                        name of XSL file's reconciled values param to parse
                        and extend.
```
